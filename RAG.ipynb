{
 "cells": [
  {
   "cell_type": "code",
   "id": "dcccaace4315033b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T03:30:27.269126Z",
     "start_time": "2024-07-12T03:30:25.920506Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "830cb80299a8160a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T03:30:30.027216Z",
     "start_time": "2024-07-12T03:30:30.005822Z"
    }
   },
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCPfSqbd0LZOz-T8CPB8bauhqsRtObE0b4'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c1c6fab0f8f84923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T05:09:25.824923Z",
     "start_time": "2024-07-12T05:07:42.885825Z"
    }
   },
   "source": [
    "loader1 = PyPDFLoader(r'C:\\Users\\jaint\\CC-Task2-RAG\\SI Chronicles 23-24 Sem I.pdf')\n",
    "loader2 = PyPDFLoader(r'C:\\Users\\jaint\\CC-Task2-RAG\\Placement Chronicles 2023-24.pdf')\n",
    "pages = loader1.load()\n",
    "pages.extend(loader2.load())\n",
    "\n",
    "print(len(pages))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "3e2196048e9fc4d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T05:10:17.468148Z",
     "start_time": "2024-07-12T05:09:50.289648Z"
    }
   },
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "39392a9324ade1c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T08:17:35.130358Z",
     "start_time": "2024-07-12T08:17:30.668780Z"
    }
   },
   "source": [
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate only the sub-problems using as little formatting as needed.\\n\n",
    "You must make them relevant from the perspective of a college student seeking help in securing placements. \\n\n",
    "Generate multiple sub-questions related to: {question} \\n\n",
    "Output (5 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries_decomposition = (prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "\n",
    "question = \"What do I need to do to secure a placement in the finance field?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\": question})\n",
    "\n",
    "questions = [q for q in questions if q]\n",
    "print(questions)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the typical career paths in finance that interest me?', 'What skills and qualifications are essential for these roles?', 'How can I gain relevant experience through internships or projects?', 'How do I network effectively within the finance industry?', 'How can I improve my resume and cover letter to stand out to potential employers? ']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T08:19:54.565724Z",
     "start_time": "2024-07-12T08:18:19.377680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"You are a helpful assistant that answers questions based on the following context: {context}\\n\n",
    "You must answer the questions from the perspective of a college student seeking help in securing placements. \\n\n",
    "Answer using as little formatting as possible.\\n\n",
    "Question: {question}\\n\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def retrieve_and_rag(prompt_rag, sub_questions):\n",
    "\n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    # Retrieve documents for each sub-question\n",
    "    hyde_template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "    Question: {question}\n",
    "    Passage:\"\"\"\n",
    "    prompt_hyde = ChatPromptTemplate.from_template(hyde_template)\n",
    "\n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        generate_docs_for_retrieval = (prompt_hyde | llm | StrOutputParser())\n",
    "        retrieval_chain = generate_docs_for_retrieval | retriever\n",
    "        retrieved_docs = retrieval_chain.invoke({\"question\": sub_question})\n",
    "\n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        ans = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs,\n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(ans)\n",
    "\n",
    "    return rag_results\n",
    "\n",
    "\n",
    "answers = retrieve_and_rag(prompt, questions)\n",
    "# print(answers)\n",
    "\n",
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "# print(context)\n",
    "\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "        prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(final_rag_chain.invoke({\"context\": context, \"question\": question}))"
   ],
   "id": "8e8cc9f9804b6048",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To secure a placement in the finance field, particularly in quantitative finance, focus on the following:\n",
      "\n",
      "**1. Technical Skills:**\n",
      "\n",
      "* **Master data structures and algorithms (DSA):** This is crucial for many quantitative roles.\n",
      "* **Develop strong coding skills:**  Focus on languages relevant to finance and data analysis.\n",
      "* **Understand core CS concepts:** Operating systems, database management systems, and object-oriented programming (OOP) are important.\n",
      "* **Gain familiarity with relevant tools:** Excel, SQL, and statistical software packages are frequently used.\n",
      "\n",
      "**2. Relevant Experience:**\n",
      "\n",
      "* **Pursue internships:** Target companies offering roles in data analytics, model validation, or related areas.\n",
      "* **Highlight relevant projects:** Showcase projects involving data analysis, financial modeling, or large datasets.\n",
      "* **Consider consulting experience:**  Experience with firms like EluciData Consulting can provide valuable exposure to handling large datasets.\n",
      "\n",
      "**3. Application Materials:**\n",
      "\n",
      "* **Tailor your resume:** Emphasize technical skills, relevant projects, and internships.\n",
      "* **Craft a strong cover letter:** Demonstrate your understanding of the company and the role, and articulate why you are a good fit. Highlight your enthusiasm and relevant experience.\n",
      "\n",
      "**4. Networking:**\n",
      "\n",
      "* **While not covered in the provided context, networking is crucial in finance.** Research and implement effective networking strategies within the industry.\n",
      "\n",
      "**5. Continuous Learning:**\n",
      "\n",
      "* **Stay updated on industry trends:** Finance is constantly evolving, so continuous learning is essential.\n",
      "\n",
      "By focusing on these areas, you can significantly increase your chances of securing a placement in the competitive field of finance. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16148af49d193d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
